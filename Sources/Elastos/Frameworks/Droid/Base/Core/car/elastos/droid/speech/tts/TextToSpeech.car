module
{
    using interface Elastos.IO.IFile;
    using interface Elastos.Core.ICharSequence;
    using interface Elastos.Utility.ISet;
    using interface Elastos.Utility.ILocale;
    using interface Elastos.Utility.IList;
    using interface Elastos.Utility.IHashMap;

    interface Elastos.Droid.Os.IBundle;
    interface Elastos.Droid.Media.IAudioAttributes;
    interface Elastos.Droid.Speech.Tts.ITextToSpeechOnUtteranceCompletedListener;
    interface Elastos.Droid.Speech.Tts.IUtteranceProgressListener;
    interface Elastos.Droid.Speech.Tts.IVoice;

    namespace Elastos {
    namespace Droid {
    namespace Speech {
    namespace Tts {

    /**
     *
     * Synthesizes speech from text for immediate playback or to create a sound file.
     * <p>A TextToSpeech instance can only be used to synthesize text once it has completed its
     * initialization. Implement the {@link TextToSpeech.OnInitListener} to be
     * notified of the completion of the initialization.<br>
     * When you are done using the TextToSpeech instance, call the {@link #shutdown()} method
     * to release the native resources used by the TextToSpeech engine.
     *
     */
    interface ITextToSpeech {
        /**
         * Denotes a successful operation.
         */
        const Int32 TTS_SUCCESS = 0;

        /**
         * Denotes a generic operation failure.
         */
        const Int32 TTS_ERROR = -1;

        /**
         * Denotes a stop requested by a client. It's used only on the service side of the API,
         * client should never expect to see this result code.
         */
        const Int32 STOPPED = -2;

        /**
         * Denotes a failure of a TTS engine to synthesize the given input.
         */
        const Int32 ERROR_SYNTHESIS = -3;

        /**
         * Denotes a failure of a TTS service.
         */
        const Int32 ERROR_SERVICE = -4;

        /**
         * Denotes a failure related to the output (audio device or a file).
         */
        const Int32 ERROR_OUTPUT = -5;

        /**
         * Denotes a failure caused by a network connectivity problems.
         */
        const Int32 ERROR_NETWORK = -6;

        /**
         * Denotes a failure caused by network timeout.
         */
        const Int32 ERROR_NETWORK_TIMEOUT = -7;

        /**
         * Denotes a failure caused by an invalid request.
         */
        const Int32 ERROR_INVALID_REQUEST = -8;

        /**
         * Denotes a failure caused by an unfinished download of the voice data.
         * @see Engine#KEY_FEATURE_NOT_INSTALLED
         */
        const Int32 ERROR_NOT_INSTALLED_YET = -9;

        /**
         * Queue mode where all entries in the playback queue (media to be played
         * and text to be synthesized) are dropped and replaced by the new entry.
         * Queues are flushed with respect to a given calling app. Entries in the queue
         * from other callees are not discarded.
         */
        const Int32 QUEUE_FLUSH = 0;

        /**
         * Queue mode where the new entry is added at the end of the playback queue.
         */

        const Int32 QUEUE_ADD = 1;
        /**
         * Queue mode where the entire playback queue is purged. This is different
         * from {@link #QUEUE_FLUSH} in that all entries are purged, not just entries
         * from a given caller.
         *
         * @hide
         */
        //static final int QUEUE_DESTROY = 2;

        /**
         * Denotes the language is available exactly as specified by the locale.
         */
        const Int32 LANG_COUNTRY_VAR_AVAILABLE = 2;

        /**
         * Denotes the language is available for the language and country specified
         * by the locale, but not the variant.
         */
        const Int32 LANG_COUNTRY_AVAILABLE = 1;

        /**
         * Denotes the language is available for the language by the locale,
         * but not the country and variant.
         */
        const Int32 LANG_AVAILABLE = 0;

        /**
         * Denotes the language data is missing.
         */
        const Int32 LANG_MISSING_DATA = -1;

        /**
         * Denotes the language is not supported.
         */
        const Int32 LANG_NOT_SUPPORTED = -2;

        /**
         * Broadcast Action: The TextToSpeech synthesizer has completed processing
         * of all the text in the speech queue.
         *
         * Note that this notifies callers when the <b>engine</b> has finished has
         * processing text data. Audio playback might not have completed (or even started)
         * at this point. If you wish to be notified when this happens, see
         * {@link OnUtteranceCompletedListener}.
         */
        //@SdkConstant(SdkConstantType.BROADCAST_INTENT_ACTION)
        const String ACTION_TTS_QUEUE_PROCESSING_COMPLETED = "android.speech.tts.TTS_QUEUE_PROCESSING_COMPLETED";

        /**
         * Releases the resources used by the TextToSpeech engine.
         * It is good practice for instance to call this method in the onDestroy() method of an Activity
         * so the TextToSpeech engine can be cleanly stopped.
         */
        Shutdown();

        /**
         * Adds a mapping between a string of text and a sound resource in a
         * package. After a call to this method, subsequent calls to
         * {@link #speak(String, int, HashMap)} will play the specified sound resource
         * if it is available, or synthesize the text it is missing.
         *
         * @param text
         *            The string of text. Example: <code>"south_south_east"</code>
         *
         * @param packagename
         *            Pass the packagename of the application that contains the
         *            resource. If the resource is in your own application (this is
         *            the most common case), then put the packagename of your
         *            application here.<br/>
         *            Example: <b>"com.google.marvin.compass"</b><br/>
         *            The packagename can be found in the AndroidManifest.xml of
         *            your application.
         *            <p>
         *            <code>&lt;manifest xmlns:android=&quot;...&quot;
         *      package=&quot;<b>com.google.marvin.compass</b>&quot;&gt;</code>
         *            </p>
         *
         * @param resourceId
         *            Example: <code>R.raw.south_south_east</code>
         *
         * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.
         */
        AddSpeech(
            [in] String text,
            [in] String packagename,
            [in] Int32 resourceId,
            [out] Int32* ret);

        /**
         * Adds a mapping between a CharSequence (may be spanned with TtsSpans) of text
         * and a sound resource in a package. After a call to this method, subsequent calls to
         * {@link #speak(String, int, HashMap)} will play the specified sound resource
         * if it is available, or synthesize the text it is missing.
         *
         * @param text
         *            The string of text. Example: <code>"south_south_east"</code>
         *
         * @param packagename
         *            Pass the packagename of the application that contains the
         *            resource. If the resource is in your own application (this is
         *            the most common case), then put the packagename of your
         *            application here.<br/>
         *            Example: <b>"com.google.marvin.compass"</b><br/>
         *            The packagename can be found in the AndroidManifest.xml of
         *            your application.
         *            <p>
         *            <code>&lt;manifest xmlns:android=&quot;...&quot;
         *      package=&quot;<b>com.google.marvin.compass</b>&quot;&gt;</code>
         *            </p>
         *
         * @param resourceId
         *            Example: <code>R.raw.south_south_east</code>
         *
         * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.
         */
        AddSpeech(
            [in] ICharSequence* text,
            [in] String packagename,
            [in] Int32 resourceId,
            [out] Int32* ret);

        /**
         * Adds a mapping between a CharSequence (may be spanned with TtsSpans and a sound file.
         * Using this, it is possible to add custom pronounciations for a string of text.
         * After a call to this method, subsequent calls to {@link #speak(String, int, HashMap)}
         * will play the specified sound resource if it is available, or synthesize the text it is
         * missing.
         *
         * @param text
         *            The string of text. Example: <code>"south_south_east"</code>
         * @param file
         *            File object pointing to the sound file.
         *
         * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.
         */
        AddSpeech(
            [in] ICharSequence* text,
            [in] IFile* file,
            [out] Int32* res);

        /**
         * Adds a mapping between a string of text and a sound file. Using this, it
         * is possible to add custom pronounciations for a string of text.
         * After a call to this method, subsequent calls to {@link #speak(String, int, HashMap)}
         * will play the specified sound resource if it is available, or synthesize the text it is
         * missing.
         *
         * @param text
         *            The string of text. Example: <code>"south_south_east"</code>
         * @param filename
         *            The full path to the sound file (for example:
         *            "/sdcard/mysounds/hello.wav")
         *
         * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.
         */
        AddSpeech(
            [in] String text,
            [in] String filename,
            [out] Int32* ret);

        /**
         * Adds a mapping between a string of text and a sound resource in a
         * package. Use this to add custom earcons.
         *
         * @see #playEarcon(String, int, HashMap)
         *
         * @param earcon The name of the earcon.
         *            Example: <code>"[tick]"</code><br/>
         *
         * @param packagename
         *            the package name of the application that contains the
         *            resource. This can for instance be the package name of your own application.
         *            Example: <b>"com.google.marvin.compass"</b><br/>
         *            The package name can be found in the AndroidManifest.xml of
         *            the application containing the resource.
         *            <p>
         *            <code>&lt;manifest xmlns:android=&quot;...&quot;
         *      package=&quot;<b>com.google.marvin.compass</b>&quot;&gt;</code>
         *            </p>
         *
         * @param resourceId
         *            Example: <code>R.raw.tick_snd</code>
         *
         * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.
         */
        AddEarcon(
            [in] String earcon,
            [in] String packagename,
            [in] Int32 resourceId,
            [out] Int32* ret);

        /**
         * Adds a mapping between a string of text and a sound file.
         * Use this to add custom earcons.
         *
         * @see #playEarcon(String, int, HashMap)
         *
         * @param earcon
         *            The name of the earcon.
         *            Example: <code>"[tick]"</code>
         * @param filename
         *            The full path to the sound file (for example:
         *            "/sdcard/mysounds/tick.wav")
         *
         * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.
         *
         * @deprecated As of API level 21, replaced by
         *         {@link #addEarcon(String, File)}.
         * @Deprecated
         */
        AddEarcon(
            [in] String earcon,
            [in] String filename,
            [out] Int32* ret);

        /**
         * Adds a mapping between a string of text and a sound file.
         * Use this to add custom earcons.
         *
         * @see #playEarcon(String, int, HashMap)
         *
         * @param earcon
         *            The name of the earcon.
         *            Example: <code>"[tick]"</code>
         * @param file
         *            File object pointing to the sound file.
         *
         * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.
         */
        AddEarcon(
            [in] String earcon,
            [in] IFile* file,
            [out] Int32* ret);

        /**
         * Speaks the text using the specified queuing strategy and speech parameters, the text may
         * be spanned with TtsSpans.
         * This method is asynchronous, i.e. the method just adds the request to the queue of TTS
         * requests and then returns. The synthesis might not have finished (or even started!) at the
         * time when this method returns. In order to reliably detect errors during synthesis,
         * we recommend setting an utterance progress listener (see
         * {@link #setOnUtteranceProgressListener}) and using the
         * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.
         *
         * @param text The string of text to be spoken. No longer than
         *            {@link #getMaxSpeechInputLength()} characters.
         * @param queueMode The queuing strategy to use, {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.
         * @param params Parameters for the request. Can be null.
         *            Supported parameter names:
         *            {@link Engine#KEY_PARAM_STREAM},
         *            {@link Engine#KEY_PARAM_VOLUME},
         *            {@link Engine#KEY_PARAM_PAN}.
         *            Engine specific parameters may be passed in but the parameter keys
         *            must be prefixed by the name of the engine they are intended for. For example
         *            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
         *            engine named "com.svox.pico" if it is being used.
         * @param utteranceId An unique identifier for this request.
         *
         * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the speak operation.
         */
        Speak(
            [in] ICharSequence* text,
            [in] Int32 queueMode,
            [in] IBundle* params,
            [in] String utteranceId,
            [out] Int32* ret);

        /**
         * Speaks the string using the specified queuing strategy and speech parameters.
         * This method is asynchronous, i.e. the method just adds the request to the queue of TTS
         * requests and then returns. The synthesis might not have finished (or even started!) at the
         * time when this method returns. In order to reliably detect errors during synthesis,
         * we recommend setting an utterance progress listener (see
         * {@link #setOnUtteranceProgressListener}) and using the
         * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.
         *
         * @param text The string of text to be spoken. No longer than
         *            {@link #getMaxSpeechInputLength()} characters.
         * @param queueMode The queuing strategy to use, {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.
         * @param params Parameters for the request. Can be null.
         *            Supported parameter names:
         *            {@link Engine#KEY_PARAM_STREAM},
         *            {@link Engine#KEY_PARAM_UTTERANCE_ID},
         *            {@link Engine#KEY_PARAM_VOLUME},
         *            {@link Engine#KEY_PARAM_PAN}.
         *            Engine specific parameters may be passed in but the parameter keys
         *            must be prefixed by the name of the engine they are intended for. For example
         *            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
         *            engine named "com.svox.pico" if it is being used.
         *
         * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the speak operation.
         * @deprecated As of API level 21, replaced by
         *         {@link #speak(CharSequence, int, Bundle, String)}.
         * @Deprecated
         */
        Speak(
            [in] String text,
            [in] Int32 queueMode,
            [in] IHashMap* params,
            [out] Int32* ret);

        /**
         * Plays the earcon using the specified queueing mode and parameters.
         * The earcon must already have been added with {@link #addEarcon(String, String)} or
         * {@link #addEarcon(String, String, int)}.
         * This method is asynchronous, i.e. the method just adds the request to the queue of TTS
         * requests and then returns. The synthesis might not have finished (or even started!) at the
         * time when this method returns. In order to reliably detect errors during synthesis,
         * we recommend setting an utterance progress listener (see
         * {@link #setOnUtteranceProgressListener}) and using the
         * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.
         *
         * @param earcon The earcon that should be played
         * @param queueMode {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.
         * @param params Parameters for the request. Can be null.
         *            Supported parameter names:
         *            {@link Engine#KEY_PARAM_STREAM},
         *            Engine specific parameters may be passed in but the parameter keys
         *            must be prefixed by the name of the engine they are intended for. For example
         *            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
         *            engine named "com.svox.pico" if it is being used.
         *
         * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the playEarcon operation.
         */
        PlayEarcon(
            [in] String earcon,
            [in] Int32 queueMode,
            [in] IBundle* params,
            [in] String utteranceld,
            [out] Int32* ret);

        /**
         * Plays the earcon using the specified queueing mode and parameters.
         * The earcon must already have been added with {@link #addEarcon(String, String)} or
         * {@link #addEarcon(String, String, int)}.
         * This method is asynchronous, i.e. the method just adds the request to the queue of TTS
         * requests and then returns. The synthesis might not have finished (or even started!) at the
         * time when this method returns. In order to reliably detect errors during synthesis,
         * we recommend setting an utterance progress listener (see
         * {@link #setOnUtteranceProgressListener}) and using the
         * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.
         *
         * @param earcon The earcon that should be played
         * @param queueMode {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.
         * @param params Parameters for the request. Can be null.
         *            Supported parameter names:
         *            {@link Engine#KEY_PARAM_STREAM},
         *            {@link Engine#KEY_PARAM_UTTERANCE_ID}.
         *            Engine specific parameters may be passed in but the parameter keys
         *            must be prefixed by the name of the engine they are intended for. For example
         *            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
         *            engine named "com.svox.pico" if it is being used.
         *
         * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the playEarcon operation.
         * @deprecated As of API level 21, replaced by
         *         {@link #playEarcon(String, int, Bundle, String)}.
         * @Deprecated
         */
        PlayEarcon(
            [in] String earcon,
            [in] Int32 queueMode,
            [in] IHashMap* params,
            [out] Int32* ret);

        /**
         * Plays silence for the specified amount of time using the specified
         * queue mode.
         * This method is asynchronous, i.e. the method just adds the request to the queue of TTS
         * requests and then returns. The synthesis might not have finished (or even started!) at the
         * time when this method returns. In order to reliably detect errors during synthesis,
         * we recommend setting an utterance progress listener (see
         * {@link #setOnUtteranceProgressListener}) and using the
         * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.
         *
         * @param durationInMs The duration of the silence.
         * @param queueMode {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.
         * @param utteranceId An unique identifier for this request.
         *
         * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the playSilentUtterance operation.
         */
        PlaySilentUtterance(
            [in] Int64 durationInMs,
            [in] Int32 queueMode,
            [in] String utteranceId,
            [out] Int32* ret);

        /**
         * Plays silence for the specified amount of time using the specified
         * queue mode.
         * This method is asynchronous, i.e. the method just adds the request to the queue of TTS
         * requests and then returns. The synthesis might not have finished (or even started!) at the
         * time when this method returns. In order to reliably detect errors during synthesis,
         * we recommend setting an utterance progress listener (see
         * {@link #setOnUtteranceProgressListener}) and using the
         * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.
         *
         * @param durationInMs The duration of the silence.
         * @param queueMode {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.
         * @param params Parameters for the request. Can be null.
         *            Supported parameter names:
         *            {@link Engine#KEY_PARAM_UTTERANCE_ID}.
         *            Engine specific parameters may be passed in but the parameter keys
         *            must be prefixed by the name of the engine they are intended for. For example
         *            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
         *            engine named "com.svox.pico" if it is being used.
         *
         * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the playSilence operation.
         * @deprecated As of API level 21, replaced by
         *         {@link #playSilentUtterance(long, int, String)}.
         * @Deprecated
         */
        PlaySilence(
            [in] Int64 durationInMs,
            [in] Int32 queueMode,
            [in] IHashMap* params,
            [out] Int32* ret);

        /**
         * Queries the engine for the set of features it supports for a given locale.
         * Features can either be framework defined, e.g.
         * {@link TextToSpeech.Engine#KEY_FEATURE_NETWORK_SYNTHESIS} or engine specific.
         * Engine specific keys must be prefixed by the name of the engine they
         * are intended for. These keys can be used as parameters to
         * {@link TextToSpeech#speak(String, int, java.util.HashMap)} and
         * {@link TextToSpeech#synthesizeToFile(String, java.util.HashMap, String)}.
         *
         * Features values are strings and their values must meet restrictions described in their
         * documentation.
         *
         * @param locale The locale to query features for.
         * @return Set instance. May return {@code null} on error.
         * @deprecated As of API level 21, please use voices. In order to query features of the voice,
         * call {@link #getVoices()} to retrieve the list of available voices and
         * {@link Voice#getFeatures()} to retrieve the set of features.
         * @Deprecated
         */
        //public Set<String>
        GetFeatures(
            [in] ILocale* locale,
            [out] ISet** ret);

        /**
         * Checks whether the TTS engine is busy speaking. Note that a speech item is
         * considered complete once it's audio data has been sent to the audio mixer, or
         * written to a file. There might be a finite lag between this point, and when
         * the audio hardware completes playback.
         *
         * @return {@code true} if the TTS engine is speaking.
         */
        IsSpeaking(
            [out] Boolean* ret);

        /**
         * Interrupts the current utterance (whether played or rendered to file) and discards other
         * utterances in the queue.
         *
         * @return {@link #ERROR} or {@link #SUCCESS}.
         */
        Stop(
            [out] Int32* ret);

        /**
         * Sets the speech rate.
         *
         * This has no effect on any pre-recorded speech.
         *
         * @param speechRate Speech rate. {@code 1.0} is the normal speech rate,
         *            lower values slow down the speech ({@code 0.5} is half the normal speech rate),
         *            greater values accelerate it ({@code 2.0} is twice the normal speech rate).
         *
         * @return {@link #ERROR} or {@link #SUCCESS}.
         */
        SetSpeechRate(
            [in] Float speechRate,
            [out] Int32* ret);

        /**
         * Sets the speech pitch for the TextToSpeech engine.
         *
         * This has no effect on any pre-recorded speech.
         *
         * @param pitch Speech pitch. {@code 1.0} is the normal pitch,
         *            lower values lower the tone of the synthesized voice,
         *            greater values increase it.
         *
         * @return {@link #ERROR} or {@link #SUCCESS}.
         */
        SetPitch(
            [in] Float pitch,
            [out] Int32* ret);

        /**
         * Sets the audio attributes to be used when speaking text or playing
         * back a file.
         *
         * @param audioAttributes Valid AudioAttributes instance.
         *
         * @return {@link #ERROR} or {@link #SUCCESS}.
         */
        SetAudioAttributes(
            [in] IAudioAttributes* audioAttributes,
            [out] Int32* ret);

        /**
         * @return the engine currently in use by this TextToSpeech instance.
         * @hide
         */
        GetCurrentEngine(
            [out] String* ret);

        /**
         * Returns a Locale instance describing the language currently being used as the default
         * Text-to-speech language.
         *
         * The locale object returned by this method is NOT a valid one. It has identical form to the
         * one in {@link #getLanguage()}. Please refer to {@link #getLanguage()} for more information.
         *
         * @return language, country (if any) and variant (if any) used by the client stored in a
         *     Locale instance, or {@code null} on error.
         * @deprecated As of API level 21, use <code>getDefaultVoice().getLocale()</code> ({@link
         *   #getDefaultVoice()})
         * @Deprecated
         */
        GetDefaultLanguage(
            [out] ILocale** language);

        /**
         * Sets the text-to-speech language.
         * The TTS engine will try to use the closest match to the specified
         * language as represented by the Locale, but there is no guarantee that the exact same Locale
         * will be used. Use {@link #isLanguageAvailable(Locale)} to check the level of support
         * before choosing the language to use for the next utterances.
         *
         * This method sets the current voice to the default one for the given Locale;
         * {@link #getVoice()} can be used to retrieve it.
         *
         * @param loc The locale describing the language to be used.
         *
         * @return Code indicating the support status for the locale. See {@link #LANG_AVAILABLE},
         *         {@link #LANG_COUNTRY_AVAILABLE}, {@link #LANG_COUNTRY_VAR_AVAILABLE},
         *         {@link #LANG_MISSING_DATA} and {@link #LANG_NOT_SUPPORTED}.
         */
        SetLanguage(
            [in] ILocale* loc,
            [out] Int32* ret);

        /**
         * Returns a Locale instance describing the language currently being used for synthesis
         * requests sent to the TextToSpeech engine.
         *
         * In Android 4.2 and before (API <= 17) this function returns the language that is currently
         * being used by the TTS engine. That is the last language set by this or any other
         * client by a {@link TextToSpeech#setLanguage} call to the same engine.
         *
         * In Android versions after 4.2 this function returns the language that is currently being
         * used for the synthesis requests sent from this client. That is the last language set
         * by a {@link TextToSpeech#setLanguage} call on this instance.
         *
         * If a voice is set (by {@link #setVoice(Voice)}), getLanguage will return the language of
         * the currently set voice.
         *
         * Please note that the Locale object returned by this method is NOT a valid Locale object. Its
         * language field contains a three-letter ISO 639-2/T code (where a proper Locale would use
         * a two-letter ISO 639-1 code), and the country field contains a three-letter ISO 3166 country
         * code (where a proper Locale would use a two-letter ISO 3166-1 code).
         *
         * @return language, country (if any) and variant (if any) used by the client stored in a
         *     Locale instance, or {@code null} on error.
         *
         * @deprecated As of API level 21, please use <code>getVoice().getLocale()</code>
         * ({@link #getVoice()}).
         * @Deprecated
         */
        GetLanguage(
            [out] ILocale** ret);

        /**
         * Query the engine about the set of available languages.
         */
        GetAvailableLanguages(
            [out] ISet** languages);

        /**
         * Query the engine about the set of available voices.
         *
         * Each TTS Engine can expose multiple voices for each locale, each with a different set of
         * features.
         *
         * @see #setVoice(Voice)
         * @see Voice
         */
        GetVoices(
            [out] ISet** voices);

        /**
         * Sets the text-to-speech voice.
         *
         * @param voice One of objects returned by {@link #getVoices()}.
         *
         * @return {@link #ERROR} or {@link #SUCCESS}.
         *
         * @see #getVoices
         * @see Voice
         */
        SetVoice(
            [in] IVoice* voice,
            [out] Int32* ret);

        /**
         * Returns a Voice instance describing the voice currently being used for synthesis
         * requests sent to the TextToSpeech engine.
         *
         * @return Voice instance used by the client, or {@code null} if not set or on error.
         *
         * @see #getVoices
         * @see #setVoice
         * @see Voice
         */
        GetVoice(
            [out] IVoice** voice);

        /**
         * Returns a Voice instance that's the default voice for the default Text-to-speech language.
         * @return The default voice instance for the default language, or {@code null} if not set or
         *     on error.
         */
        GetDefaultVoice(
            [out] IVoice** voice);

        /**
         * Checks if the specified language as represented by the Locale is available and supported.
         *
         * @param loc The Locale describing the language to be used.
         *
         * @return Code indicating the support status for the locale. See {@link #LANG_AVAILABLE},
         *         {@link #LANG_COUNTRY_AVAILABLE}, {@link #LANG_COUNTRY_VAR_AVAILABLE},
         *         {@link #LANG_MISSING_DATA} and {@link #LANG_NOT_SUPPORTED}.
         */
        IsLanguageAvailable(
            [in] ILocale* loc,
            [out] Int32* ret);

        /**
         * Synthesizes the given text to a file using the specified parameters.
         * This method is asynchronous, i.e. the method just adds the request to the queue of TTS
         * requests and then returns. The synthesis might not have finished (or even started!) at the
         * time when this method returns. In order to reliably detect errors during synthesis,
         * we recommend setting an utterance progress listener (see
         * {@link #setOnUtteranceProgressListener}).
         *
         * @param text The text that should be synthesized. No longer than
         *            {@link #getMaxSpeechInputLength()} characters.
         * @param params Parameters for the request. Can be null.
         *            Engine specific parameters may be passed in but the parameter keys
         *            must be prefixed by the name of the engine they are intended for. For example
         *            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
         *            engine named "com.svox.pico" if it is being used.
         * @param file File to write the generated audio data to.
         * @param utteranceId An unique identifier for this request.
         * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the synthesizeToFile operation.
         */
        SynthesizeToFile(
            [in] ICharSequence* text,
            [in] IBundle* params,
            [in] IFile* filename,
            [in] String utteranceld,
            [out] Int32* ret);

        /**
         * Synthesizes the given text to a file using the specified parameters.
         * This method is asynchronous, i.e. the method just adds the request to the queue of TTS
         * requests and then returns. The synthesis might not have finished (or even started!) at the
         * time when this method returns. In order to reliably detect errors during synthesis,
         * we recommend setting an utterance progress listener (see
         * {@link #setOnUtteranceProgressListener}) and using the
         * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.
         *
         * @param text The text that should be synthesized. No longer than
         *            {@link #getMaxSpeechInputLength()} characters.
         * @param params Parameters for the request. Can be null.
         *            Supported parameter names:
         *            {@link Engine#KEY_PARAM_UTTERANCE_ID}.
         *            Engine specific parameters may be passed in but the parameter keys
         *            must be prefixed by the name of the engine they are intended for. For example
         *            the keys "com.svox.pico_foo" and "com.svox.pico:bar" will be passed to the
         *            engine named "com.svox.pico" if it is being used.
         * @param filename Absolute file filename to write the generated audio data to.It should be
         *            something like "/sdcard/myappsounds/mysound.wav".
         *
         * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the synthesizeToFile operation.
         * @deprecated As of API level 21, replaced by
         *         {@link #synthesizeToFile(CharSequence, Bundle, File, String)}.
         * @Deprecated
         */
        SynthesizeToFile(
            [in] String text,
            [in] IHashMap* params,
            [in] String filename,
            [out] Int32* ret);

        /**
         * Sets the listener that will be notified when synthesis of an utterance completes.
         *
         * @param listener The listener to use.
         *
         * @return {@link #ERROR} or {@link #SUCCESS}.
         *
         * @deprecated Use {@link #setOnUtteranceProgressListener(UtteranceProgressListener)}
         *        instead.
         */
        //@Deprecated
        SetOnUtteranceCompletedListener(
            [in] ITextToSpeechOnUtteranceCompletedListener* listener,
            [out] Int32* ret);

        /**
         * Sets the listener that will be notified of various events related to the
         * synthesis of a given utterance.
         *
         * See {@link UtteranceProgressListener} and
         * {@link TextToSpeech.Engine#KEY_PARAM_UTTERANCE_ID}.
         *
         * @param listener the listener to use.
         * @return {@link #ERROR} or {@link #SUCCESS}
         */
        SetOnUtteranceProgressListener(
            [in] IUtteranceProgressListener* listener,
            [out] Int32* ret);

        /**
         * Sets the TTS engine to use.
         *
         * @deprecated This doesn't inform callers when the TTS engine has been
         *        initialized. {@link #TextToSpeech(Context, OnInitListener, String)}
         *        can be used with the appropriate engine name. Also, there is no
         *        guarantee that the engine specified will be loaded. If it isn't
         *        installed or disabled, the user / system wide defaults will apply.
         *
         * @param enginePackageName The package name for the synthesis engine (e.g. "com.svox.pico")
         *
         * @return {@link #ERROR} or {@link #SUCCESS}.
         */
        //@Deprecated
        SetEngineByPackageName(
            [in] String enginePackageName,
            [out] Int32* ret);

        /**
         * Gets the package name of the default speech synthesis engine.
         *
         * @return Package name of the TTS engine that the user has chosen
         *        as their default.
         */
        GetDefaultEngine(
            [out] String* ret);

        /**
         * Checks whether the user's settings should override settings requested
         * by the calling application. As of the Ice cream sandwich release,
         * user settings never forcibly override the app's settings.
         */
        AreDefaultsEnforced(
            [out] Boolean* ret);

        /**
         * Gets a list of all installed TTS engines.
         *
         * @return A list of engine info objects. The list can be empty, but never {@code null}.
         */
        //public List<EngineInfo>
        GetEngines(
            [out] IList** ret);
    }

    /**
     * Interface definition of a callback to be invoked indicating the completion of the
     * TextToSpeech engine initialization.
     */
    //public interface
    interface ITextToSpeechOnInitListener {
        /**
         * Called to signal the completion of the TextToSpeech engine initialization.
         *
         * @param status {@link TextToSpeech#SUCCESS} or {@link TextToSpeech#ERROR}.
         */
        OnInit(
            [in] Int32 status);
    }

    /**
     * Listener that will be called when the TTS service has
     * completed synthesizing an utterance. This is only called if the utterance
     * has an utterance ID (see {@link TextToSpeech.Engine#KEY_PARAM_UTTERANCE_ID}).
     */
    //public interface
    interface ITextToSpeechOnUtteranceCompletedListener {
        /**
         * Called when an utterance has been synthesized.
         *
         * @param utteranceId the identifier of the utterance.
         */
        OnUtteranceCompleted(
            [in] String utteranceId);
    }

    /**
     * Constants and parameter names for controlling text-to-speech. These include:
     *
     * <ul>
     *     <li>
     *         Intents to ask engine to install data or check its data and
     *         extras for a TTS engine's check data activity.
     *     </li>
     *     <li>
     *         Keys for the parameters passed with speak commands, e.g.
     *         {@link Engine#KEY_PARAM_UTTERANCE_ID}, {@link Engine#KEY_PARAM_STREAM}.
     *     </li>
     *     <li>
     *         A list of feature strings that engines might support, e.g
     *         {@link Engine#KEY_FEATURE_NETWORK_SYNTHESIS}). These values may be passed in to
     *         {@link TextToSpeech#speak} and {@link TextToSpeech#synthesizeToFile} to modify
     *         engine behaviour. The engine can be queried for the set of features it supports
     *         through {@link TextToSpeech#getFeatures(java.util.Locale)}.
     *     </li>
     * </ul>
     */
    //public class
    interface ITextToSpeechEngine {

        /**
         * Default speech rate.
         * @hide
         */
        const Int32 DEFAULT_RATE = 100;

        /**
         * Default pitch.
         * @hide
         */
        const Int32 DEFAULT_PITCH = 100;

        /**
         * Default volume.
         * @hide
         */
        const Float DEFAULT_VOLUME = 1.0;

        /**
         * Default pan (centered).
         * @hide
         */
        const Float DEFAULT_PAN = 0.0;

        /**
         * Default value for {@link Settings.Secure#TTS_USE_DEFAULTS}.
         * @hide
         */
        const Int32 USE_DEFAULTS = 0; // false

        /**
         * Package name of the default TTS engine.
         *
         * @hide
         * @deprecated No longer in use, the default engine is determined by
         *         the sort order defined in {@link TtsEngines}. Note that
         *         this doesn't "break" anything because there is no guarantee that
         *         the engine specified below is installed on a given build, let
         *         alone be the default.
         * @Deprecated
         */
        const String DEFAULT_ENGINE = "com.svox.pico";

        /**
         * Default audio stream used when playing synthesized speech.
         */
        const Int32 DEFAULT_STREAM = 3; //AudioManager.STREAM_MUSIC;

        /**
         * Indicates success when checking the installation status of the resources used by the
         * TextToSpeech engine with the {@link #ACTION_CHECK_TTS_DATA} intent.
         */
        const Int32 CHECK_VOICE_DATA_PASS = 1;

        /**
         * Indicates failure when checking the installation status of the resources used by the
         * TextToSpeech engine with the {@link #ACTION_CHECK_TTS_DATA} intent.
         */
        const Int32 CHECK_VOICE_DATA_FAIL = 0;

        /**
         * Indicates erroneous data when checking the installation status of the resources used by
         * the TextToSpeech engine with the {@link #ACTION_CHECK_TTS_DATA} intent.
         *
         * @deprecated Use CHECK_VOICE_DATA_FAIL instead.
         * @Deprecated
         */
        const Int32 CHECK_VOICE_DATA_BAD_DATA = -1;

        /**
         * Indicates missing resources when checking the installation status of the resources used
         * by the TextToSpeech engine with the {@link #ACTION_CHECK_TTS_DATA} intent.
         *
         * @deprecated Use CHECK_VOICE_DATA_FAIL instead.
         * @Deprecated
         */
        const Int32 CHECK_VOICE_DATA_MISSING_DATA = -2;

        /**
         * Indicates missing storage volume when checking the installation status of the resources
         * used by the TextToSpeech engine with the {@link #ACTION_CHECK_TTS_DATA} intent.
         *
         * @deprecated Use CHECK_VOICE_DATA_FAIL instead.
         * @Deprecated
         */
        const Int32 CHECK_VOICE_DATA_MISSING_VOLUME = -3;

        /**
         * Intent for starting a TTS service. Services that handle this intent must
         * extend {@link TextToSpeechService}. Normal applications should not use this intent
         * directly, instead they should talk to the TTS service using the the methods in this
         * class.
         * @SdkConstant(SdkConstantType.SERVICE_ACTION)
         */
        const String INTENT_ACTION_TTS_SERVICE =
            "android.intent.action.TTS_SERVICE";

        /**
         * Name under which a text to speech engine publishes information about itself.
         * This meta-data should reference an XML resource containing a
         * <code>&lt;{@link android.R.styleable#TextToSpeechEngine tts-engine}&gt;</code>
         * tag.
         */
        const String SERVICE_META_DATA = "android.speech.tts";

        // intents to ask engine to install data or check its data
        /**
         * Activity Action: Triggers the platform TextToSpeech engine to
         * start the activity that installs the resource files on the device
         * that are required for TTS to be operational. Since the installation
         * of the data can be interrupted or declined by the user, the application
         * shouldn't expect successful installation upon return from that intent,
         * and if need be, should check installation status with
         * {@link #ACTION_CHECK_TTS_DATA}.
         * @SdkConstant(SdkConstantType.ACTIVITY_INTENT_ACTION)
         */
        const String ACTION_INSTALL_TTS_DATA =
            "android.speech.tts.engine.INSTALL_TTS_DATA";

        /**
         * Broadcast Action: broadcast to signal the change in the list of available
         * languages or/and their features.
         * @SdkConstant(SdkConstantType.BROADCAST_INTENT_ACTION)
         */
        const String ACTION_TTS_DATA_INSTALLED =
            "android.speech.tts.engine.TTS_DATA_INSTALLED";

        /**
         * Activity Action: Starts the activity from the platform TextToSpeech
         * engine to verify the proper installation and availability of the
         * resource files on the system. Upon completion, the activity will
         * return one of the following codes:
         * {@link #CHECK_VOICE_DATA_PASS},
         * {@link #CHECK_VOICE_DATA_FAIL},
         * <p> Moreover, the data received in the activity result will contain the following
         * fields:
         * <ul>
         *   <li>{@link #EXTRA_AVAILABLE_VOICES} which contains an ArrayList<String> of all the
         *   available voices. The format of each voice is: lang-COUNTRY-variant where COUNTRY and
         *   variant are optional (ie, "eng" or "eng-USA" or "eng-USA-FEMALE").</li>
         *   <li>{@link #EXTRA_UNAVAILABLE_VOICES} which contains an ArrayList<String> of all the
         *   unavailable voices (ones that user can install). The format of each voice is:
         *   lang-COUNTRY-variant where COUNTRY and variant are optional (ie, "eng" or
         *   "eng-USA" or "eng-USA-FEMALE").</li>
         * </ul>
         * @SdkConstant(SdkConstantType.ACTIVITY_INTENT_ACTION)
         */
        const String ACTION_CHECK_TTS_DATA =
            "android.speech.tts.engine.CHECK_TTS_DATA";

        /**
         * Activity intent for getting some sample text to use for demonstrating TTS. Specific
         * locale have to be requested by passing following extra parameters:
         * <ul>
         *   <li>language</li>
         *   <li>country</li>
         *   <li>variant</li>
         * </ul>
         *
         * Upon completion, the activity result may contain the following fields:
         * <ul>
         *   <li>{@link #EXTRA_SAMPLE_TEXT} which contains an String with sample text.</li>
         * </ul>
         * @SdkConstant(SdkConstantType.ACTIVITY_INTENT_ACTION)
         */
        const String ACTION_GET_SAMPLE_TEXT =
            "android.speech.tts.engine.GET_SAMPLE_TEXT";

        /**
         * Extra information received with the {@link #ACTION_GET_SAMPLE_TEXT} intent result where
         * the TextToSpeech engine returns an String with sample text for requested voice
         */
        const String EXTRA_SAMPLE_TEXT = "sampleText";


        // extras for a TTS engine's check data activity
        /**
         * Extra information received with the {@link #ACTION_CHECK_TTS_DATA} intent result where
         * the TextToSpeech engine returns an ArrayList<String> of all the available voices.
         * The format of each voice is: lang-COUNTRY-variant where COUNTRY and variant are
         * optional (ie, "eng" or "eng-USA" or "eng-USA-FEMALE").
         */
        const String EXTRA_AVAILABLE_VOICES = "availableVoices";

        /**
         * Extra information received with the {@link #ACTION_CHECK_TTS_DATA} intent result where
         * the TextToSpeech engine returns an ArrayList<String> of all the unavailable voices.
         * The format of each voice is: lang-COUNTRY-variant where COUNTRY and variant are
         * optional (ie, "eng" or "eng-USA" or "eng-USA-FEMALE").
         */
        const String EXTRA_UNAVAILABLE_VOICES = "unavailableVoices";

        /**
         * Extra information received with the {@link #ACTION_CHECK_TTS_DATA} intent result where
         * the TextToSpeech engine specifies the path to its resources.
         *
         * It may be used by language packages to find out where to put their data.
         *
         * @deprecated TTS engine implementation detail, this information has no use for
         * text-to-speech API client.
         * @Deprecated
         */
        const String EXTRA_VOICE_DATA_ROOT_DIRECTORY = "dataRoot";

        /**
         * Extra information received with the {@link #ACTION_CHECK_TTS_DATA} intent result where
         * the TextToSpeech engine specifies the file names of its resources under the
         * resource path.
         *
         * @deprecated TTS engine implementation detail, this information has no use for
         * text-to-speech API client.
         * @Deprecated
         */
        const String EXTRA_VOICE_DATA_FILES = "dataFiles";

        /**
         * Extra information received with the {@link #ACTION_CHECK_TTS_DATA} intent result where
         * the TextToSpeech engine specifies the locale associated with each resource file.
         *
         * @deprecated TTS engine implementation detail, this information has no use for
         * text-to-speech API client.
         * @Deprecated
         */
        const String EXTRA_VOICE_DATA_FILES_INFO = "dataFilesInfo";

        /**
         * Extra information sent with the {@link #ACTION_CHECK_TTS_DATA} intent where the
         * caller indicates to the TextToSpeech engine which specific sets of voice data to
         * check for by sending an ArrayList<String> of the voices that are of interest.
         * The format of each voice is: lang-COUNTRY-variant where COUNTRY and variant are
         * optional (ie, "eng" or "eng-USA" or "eng-USA-FEMALE").
         *
         * @deprecated Redundant functionality, checking for existence of specific sets of voice
         * data can be done on client side.
         * @Deprecated
         */
        const String EXTRA_CHECK_VOICE_DATA_FOR = "checkVoiceDataFor";

        // extras for a TTS engine's data installation
        /**
         * Extra information received with the {@link #ACTION_TTS_DATA_INSTALLED} intent result.
         * It indicates whether the data files for the synthesis engine were successfully
         * installed. The installation was initiated with the  {@link #ACTION_INSTALL_TTS_DATA}
         * intent. The possible values for this extra are
         * {@link TextToSpeech#SUCCESS} and {@link TextToSpeech#ERROR}.
         *
         * @deprecated No longer in use. If client ise interested in information about what
         * changed, is should send ACTION_CHECK_TTS_DATA intent to discover available voices.
         * @Deprecated
         */
        const String EXTRA_TTS_DATA_INSTALLED = "dataInstalled";

        // keys for the parameters passed with speak commands. Hidden keys are used internally
        // to maintain engine state for each TextToSpeech instance.
        /**
         * @hide
         */
        const String KEY_PARAM_RATE = "rate";

        /**
         * @hide
         */
        const String KEY_PARAM_VOICE_NAME = "voiceName";

        /**
         * @hide
         */
        const String KEY_PARAM_LANGUAGE = "language";

        /**
         * @hide
         */
        const String KEY_PARAM_COUNTRY = "country";

        /**
         * @hide
         */
        const String KEY_PARAM_VARIANT = "variant";

        /**
         * @hide
         */
        const String KEY_PARAM_ENGINE = "engine";

        /**
         * @hide
         */
        const String KEY_PARAM_PITCH = "pitch";

        /**
         * Parameter key to specify the audio stream type to be used when speaking text
         * or playing back a file. The value should be one of the STREAM_ constants
         * defined in {@link AudioManager}.
         *
         * @see TextToSpeech#speak(String, int, HashMap)
         * @see TextToSpeech#playEarcon(String, int, HashMap)
         */
        const String KEY_PARAM_STREAM = "streamType";

        /**
         * Parameter key to specify the audio attributes to be used when
         * speaking text or playing back a file. The value should be set
         * using {@link TextToSpeech#setAudioAttributes(AudioAttributes)}.
         *
         * @see TextToSpeech#speak(String, int, HashMap)
         * @see TextToSpeech#playEarcon(String, int, HashMap)
         * @hide
         */
        const String KEY_PARAM_AUDIO_ATTRIBUTES = "audioAttributes";

        /**
         * Parameter key to identify an utterance in the
         * {@link TextToSpeech.OnUtteranceCompletedListener} after text has been
         * spoken, a file has been played back or a silence duration has elapsed.
         *
         * @see TextToSpeech#speak(String, int, HashMap)
         * @see TextToSpeech#playEarcon(String, int, HashMap)
         * @see TextToSpeech#synthesizeToFile(String, HashMap, String)
         */
        const String KEY_PARAM_UTTERANCE_ID = "utteranceId";

        /**
         * Parameter key to specify the speech volume relative to the current stream type
         * volume used when speaking text. Volume is specified as a float ranging from 0 to 1
         * where 0 is silence, and 1 is the maximum volume (the default behavior).
         *
         * @see TextToSpeech#speak(String, int, HashMap)
         * @see TextToSpeech#playEarcon(String, int, HashMap)
         */
        const String KEY_PARAM_VOLUME = "volume";

        /**
         * Parameter key to specify how the speech is panned from left to right when speaking text.
         * Pan is specified as a float ranging from -1 to +1 where -1 maps to a hard-left pan,
         * 0 to center (the default behavior), and +1 to hard-right.
         *
         * @see TextToSpeech#speak(String, int, HashMap)
         * @see TextToSpeech#playEarcon(String, int, HashMap)
         */
        const String KEY_PARAM_PAN = "pan";

        /**
         * Feature key for network synthesis. See {@link TextToSpeech#getFeatures(Locale)}
         * for a description of how feature keys work. If set (and supported by the engine
         * as per {@link TextToSpeech#getFeatures(Locale)}, the engine must
         * use network based synthesis.
         *
         * @see TextToSpeech#speak(String, int, java.util.HashMap)
         * @see TextToSpeech#synthesizeToFile(String, java.util.HashMap, String)
         * @see TextToSpeech#getFeatures(java.util.Locale)
         *
         * @deprecated Starting from API level 21, to select network synthesis, call
         * ({@link TextToSpeech#getVoices()}, find a suitable network voice
         * ({@link Voice#isNetworkConnectionRequired()}) and pass it
         * to {@link TextToSpeech#setVoice(Voice)}).
         * @Deprecated
         */
        const String KEY_FEATURE_NETWORK_SYNTHESIS = "networkTts";

        /**
         * Feature key for embedded synthesis. See {@link TextToSpeech#getFeatures(Locale)}
         * for a description of how feature keys work. If set and supported by the engine
         * as per {@link TextToSpeech#getFeatures(Locale)}, the engine must synthesize
         * text on-device (without making network requests).
         *
         * @see TextToSpeech#speak(String, int, java.util.HashMap)
         * @see TextToSpeech#synthesizeToFile(String, java.util.HashMap, String)
         * @see TextToSpeech#getFeatures(java.util.Locale)

         * @deprecated Starting from API level 21, to select embedded synthesis, call
         * ({@link TextToSpeech#getVoices()}, find a suitable embedded voice
         * ({@link Voice#isNetworkConnectionRequired()}) and pass it
         * to {@link TextToSpeech#setVoice(Voice)}).
         * @Deprecated
         */
        const String KEY_FEATURE_EMBEDDED_SYNTHESIS = "embeddedTts";

        /**
         * Parameter key to specify an audio session identifier (obtained from
         * {@link AudioManager#generateAudioSessionId()}) that will be used by the request audio
         * output. It can be used to associate one of the {@link android.media.audiofx.AudioEffect}
         * objects with the synthesis (or earcon) output.
         *
         * @see TextToSpeech#speak(String, int, HashMap)
         * @see TextToSpeech#playEarcon(String, int, HashMap)
         */
        const String KEY_PARAM_SESSION_ID = "sessionId";

        /**
         * Feature key that indicates that the voice may need to download additional data to be fully
         * functional. The download will be triggered by calling
         * {@link TextToSpeech#setVoice(Voice)} or {@link TextToSpeech#setLanguage(Locale)}.
         * Until download is complete, each synthesis request will either report
         * {@link TextToSpeech#ERROR_NOT_INSTALLED_YET} error, or use a different voice to synthesize
         * the request. This feature should NOT be used as a key of a request parameter.
         *
         * @see TextToSpeech#getFeatures(java.util.Locale)
         * @see Voice#getFeatures()
         */
        const String KEY_FEATURE_NOT_INSTALLED = "notInstalled";

        /**
         * Feature key that indicate that a network timeout can be set for the request. If set and
         * supported as per {@link TextToSpeech#getFeatures(Locale)} or {@link Voice#getFeatures()},
         * it can be used as request parameter to set the maximum allowed time for a single
         * request attempt, in milliseconds, before synthesis fails. When used as a key of
         * a request parameter, its value should be a string with an integer value.
         *
         * @see TextToSpeech#getFeatures(java.util.Locale)
         * @see Voice#getFeatures()
         */
        const String KEY_FEATURE_NETWORK_TIMEOUT_MS = "networkTimeoutMs";

        /**
         * Feature key that indicates that network request retries count can be set for the request.
         * If set and supported as per {@link TextToSpeech#getFeatures(Locale)} or
         * {@link Voice#getFeatures()}, it can be used as a request parameter to set the
         * number of network request retries that are attempted in case of failure. When used as
         * a key of a request parameter, its value should be a string with an integer value.
         *
         * @see TextToSpeech#getFeatures(java.util.Locale)
         * @see Voice#getFeatures()
         */
        const String KEY_FEATURE_NETWORK_RETRIES_COUNT = "networkRetriesCount";
    }

    /**
     * Information about an installed text-to-speech engine.
     *
     * @see TextToSpeech#getEngines
     */
    //public static class
    interface ITextToSpeechEngineInfo {
    }

    //private interface
    /*
    interface ITextToSpeechActionR {
        Run(
            [in] IITextToSpeechService* service,
            [out] IInterface** R);
    };
    */

    } // namespace Tts
    } // namespace Speech
    } // namespace Droid
    } // namespace Elastos

}
